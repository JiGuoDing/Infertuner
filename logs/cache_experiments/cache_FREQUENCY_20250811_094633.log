2025-08-11 09:51:28,644 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - Trying to select the network interface and address to use by connecting to the leading JobManager.
2025-08-11 09:51:28,644 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - TaskManager will try to connect for PT10S before falling back to heuristics
2025-08-11 09:51:28,883 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - TaskManager will use hostname/address 'gpu02' (127.0.0.1) for communication.
2025-08-11 09:51:28,919 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 127.0.0.1:0, bind address localhost:0.
2025-08-11 09:51:29,459 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-08-11 09:51:29,492 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-08-11 09:51:29,492 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-08-11 09:51:29,643 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@127.0.0.1:6743]
2025-08-11 09:51:29,754 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@127.0.0.1:6743
2025-08-11 09:51:29,769 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using working directory: WorkingDirectory(/tmp/tm_127.0.0.1:6743-5ad3ef)
2025-08-11 09:51:29,777 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-08-11 09:51:29,780 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 127.0.0.1:0, bind address localhost:0.
2025-08-11 09:51:29,795 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-08-11 09:51:29,798 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2025-08-11 09:51:29,805 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-08-11 09:51:29,818 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.0.1:31859]
2025-08-11 09:51:29,826 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@127.0.0.1:31859
2025-08-11 09:51:29,840 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_127.0.0.1:6743-5ad3ef .
2025-08-11 09:51:29,853 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /tmp/tm_127.0.0.1:6743-5ad3ef/blobStorage
2025-08-11 09:51:29,857 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /tmp/tm_127.0.0.1:6743-5ad3ef/blobStorage
2025-08-11 09:51:29,863 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2025-08-11 09:51:29,864 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2025-08-11 09:51:29,867 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2025-08-11 09:51:29,868 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2025-08-11 09:51:29,868 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2025-08-11 09:51:29,869 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2025-08-11 09:51:29,869 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2025-08-11 09:51:29,870 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2025-08-11 09:51:29,870 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: 127.0.0.1:6743-5ad3ef
2025-08-11 09:51:29,887 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/tmp': total 1758 GB, usable 31 GB (1.76% usable)
2025-08-11 09:51:29,891 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/tmp/flink-io-6315f033-5ba0-47e7-963d-bfc80433e295
2025-08-11 09:51:29,897 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: localhost/127.0.0.1, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 4 (manual), number of client threads: 4 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2025-08-11 09:51:29,951 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/tmp/flink-netty-shuffle-6c14e22d-75de-4e7d-9232-ec76c318a89f
2025-08-11 09:51:30,163 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 343 MB for network buffer pool (number of memory segments: 10977, bytes per segment: 32768).
2025-08-11 09:51:30,176 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2025-08-11 09:51:30,226 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2025-08-11 09:51:30,228 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 50 ms).
2025-08-11 09:51:30,232 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2025-08-11 09:51:30,286 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 57 ms). Listening on SocketAddress /127.0.0.1:11783.
2025-08-11 09:51:30,288 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2025-08-11 09:51:30,331 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2025-08-11 09:51:30,348 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2025-08-11 09:51:30,351 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /tmp/flink-dist-cache-7726864a-1872-4e40-b34d-b516d28c2fa9
2025-08-11 09:51:30,355 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2025-08-11 09:51:30,566 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2025-08-11 09:51:30,677 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 640132bedae82bf8850fd9c584516556.
2025-08-11 09:51:36,526 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 9a6f81c900ef241ce19998b167ef2d71 for job 77bcb6f409e6d90ca30dbd473ecf2d2c from resource manager with leader id 00000000000000000000000000000000.
2025-08-11 09:51:36,531 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 9a6f81c900ef241ce19998b167ef2d71.
2025-08-11 09:51:36,532 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 77bcb6f409e6d90ca30dbd473ecf2d2c for job leader monitoring.
2025-08-11 09:51:36,533 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2025-08-11 09:51:36,563 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-08-11 09:51:36,598 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 77bcb6f409e6d90ca30dbd473ecf2d2c.
2025-08-11 09:51:36,600 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 77bcb6f409e6d90ca30dbd473ecf2d2c.
2025-08-11 09:51:36,602 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 77bcb6f409e6d90ca30dbd473ecf2d2c.
2025-08-11 09:51:36,639 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 9a6f81c900ef241ce19998b167ef2d71.
2025-08-11 09:51:36,657 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2025-08-11 09:51:36,665 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id 77bcb6f409e6d90ca30dbd473ecf2d2c
2025-08-11 09:51:36,670 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 9a6f81c900ef241ce19998b167ef2d71.
2025-08-11 09:51:36,671 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2025-08-11 09:51:36,673 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 9a6f81c900ef241ce19998b167ef2d71.
2025-08-11 09:51:36,677 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2025-08-11 09:51:36,681 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 77bcb6f409e6d90ca30dbd473ecf2d2c/p-8b9a678f66a218e059efd09d05af1b3c6de3de9a-b1c772bc80b31a0dc79dffa3b3198463 from localhost/127.0.0.1:20803
2025-08-11 09:51:36,742 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: org.apache.flink.runtime.state.hashmap.HashMapStateBackend@77c79265
2025-08-11 09:51:36,742 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: org.apache.flink.runtime.state.hashmap.HashMapStateBackend@43378589
2025-08-11 09:51:36,743 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2025-08-11 09:51:36,747 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@200dd9d5
2025-08-11 09:51:36,758 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2025-08-11 09:51:36,850 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 启动模块化缓存推理服务 (策略=FREQUENCY, 初始大小=5)
2025-08-11 09:51:36,850 INFO  com.infertuner.cache.TwoLevelCacheManager                    [] - 初始化二级缓存管理器，本地缓存大小: 5
2025-08-11 09:51:41,949 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 模块化缓存推理服务已启动
2025-08-11 09:51:41,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2025-08-11 09:51:41,958 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 开始生成优化负载请求流，总数: 80
2025-08-11 09:51:44,469 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_000] 未命中: 2425.04ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=68)
2025-08-11 09:51:44,469 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #1 ===
2025-08-11 09:51:44,469 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_000 | 用户: user_001
2025-08-11 09:51:44,469 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:51:44,470 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人类大脑结构和功能的计算模型，它由多个节点（称为神经元）组成，每个神经元接收来自其他神经元的信息，并通过一系列复杂的运算过程将其转化为最终输出...
2025-08-11 09:51:44,470 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 2425.0ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:51:44,470 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:44,470 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 高度集中访问 | 活跃用户: 3个 | 每用户session: 1 | 请求间隔: 150ms | 进度: 1/80
2025-08-11 09:51:45,583 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_001] 命中: 958.37ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:45,583 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #2 ===
2025-08-11 09:51:45,584 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_001 | 用户: user_001
2025-08-11 09:51:45,584 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:51:45,584 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，其基本原理是模仿人脑的神经网络结构和工作方式，通过多层非线性变换来模拟人类大脑处理信息的过程。以下是一些主要的深度学习基本原理：

...
2025-08-11 09:51:45,584 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 958.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:45,584 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:46,444 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_002] 命中: 707.68ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:46,444 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #3 ===
2025-08-11 09:51:46,445 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_002 | 用户: user_001
2025-08-11 09:51:46,445 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:51:46,445 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer（Transformers）是一种深度学习模型，由Google在2017年提出，并被广泛应用于自然语言处理、计算机视觉和语音识别等领域。其...
2025-08-11 09:51:46,445 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 707.7ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:46,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:47,465 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_003] 命中: 866.59ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #4 ===
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_003 | 用户: user_001
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种基于模仿生物神经系统工作原理的机器学习模型，它通过多层非线性变换将输入数据映射到输出结果。其基本运作过程如下：

1. **输入层**：接收原始输...
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 866.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:47,465 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:48,508 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_004] 命中: 890.32ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:48,508 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #5 ===
2025-08-11 09:51:48,508 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_004 | 用户: user_001
2025-08-11 09:51:48,509 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:51:48,509 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能（AI）技术，它允许计算机系统通过从数据中自动学习和改进性能，而无需明确编程或进行人工干预。它的目标是使计算机系统能够根据输入的数据自动识...
2025-08-11 09:51:48,509 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 890.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:48,509 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:51:48,510 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 5 | 成功: 5 (100.0%) | 平均耗时: 1169.6ms
2025-08-11 09:51:48,510 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:49,553 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_005] 命中: 891.05ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:49,553 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #6 ===
2025-08-11 09:51:49,553 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_005 | 用户: user_001
2025-08-11 09:51:49,553 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:51:49,554 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估一个模型的质量通常涉及以下几个方面：

1. **准确性**：准确性是指模型预测结果与实际标签或数据集中的实际值之间的匹配程度。准确性可以通过计算模型的准确...
2025-08-11 09:51:49,554 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 891.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:49,554 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:50,641 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_006] 命中: 934.45ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:50,641 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #7 ===
2025-08-11 09:51:50,641 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_006 | 用户: user_001
2025-08-11 09:51:50,641 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:51:50,642 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型的质量通常包括以下几个方面：

1. 准确性：这是衡量模型性能最基本的标准。准确性是指模型预测结果与实际值之间的差异程度，通常用精度、召回率和F1分数等...
2025-08-11 09:51:50,642 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 934.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:50,642 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:52,779 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_007] 未命中: 1934.02ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=68)
2025-08-11 09:51:52,779 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #8 ===
2025-08-11 09:51:52,779 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_007 | 用户: user_002
2025-08-11 09:51:52,779 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:51:52,780 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，它使用多层神经网络来模拟人类大脑的学习过程。它的基本原理是将数据输入到多层神经网络中，每一层神经网络都会通过一系列的计算和参数调整，...
2025-08-11 09:51:52,780 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1934.0ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:51:52,780 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:53,634 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_008] 命中: 701.58ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:53,635 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #9 ===
2025-08-11 09:51:53,635 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_008 | 用户: user_001
2025-08-11 09:51:53,635 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:51:53,635 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer（Transformers）是一种深度学习模型，它由两个部分组成：编码器和解码器。下面是Transformer架构的详细解释：

1. 编...
2025-08-11 09:51:53,635 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 701.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:53,636 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:54,502 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_009] 命中: 714.57ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:54,503 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #10 ===
2025-08-11 09:51:54,503 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_009 | 用户: user_001
2025-08-11 09:51:54,503 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:51:54,503 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是一种人工智能技术，它能够模拟人类的自然语言处理能力，以理解和生成人类的语言。这种技术通常由大型预训练神经网络（如GPT-3、BERT等）构建，这...
2025-08-11 09:51:54,504 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 714.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:54,504 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:51:54,504 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 10 | 成功: 10 (100.0%) | 平均耗时: 1102.4ms
2025-08-11 09:51:54,504 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:55,447 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_010] 命中: 790.4ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:55,447 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #11 ===
2025-08-11 09:51:55,447 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_010 | 用户: user_001
2025-08-11 09:51:55,447 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:51:55,447 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人脑神经元工作的计算模型，它通过多层神经元之间的连接来处理和学习输入数据。以下是如何神经网络工作的一般步骤：

1. 数据预处理：首先，将原始...
2025-08-11 09:51:55,448 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 790.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:55,448 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:56,497 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_011] 命中: 896.81ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:56,497 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #12 ===
2025-08-11 09:51:56,497 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_011 | 用户: user_001
2025-08-11 09:51:56,497 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:51:56,497 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是一种人工智能技术，它使用深度学习算法和大规模语料库来理解和生成人类语言。这种技术可以模拟人类的自然语言处理能力，例如理解、生成和回答问题，进行对...
2025-08-11 09:51:56,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 896.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:56,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:57,383 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_012] 命中: 733.53ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #13 ===
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_012 | 用户: user_002
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它使用算法和统计模型来让计算机从数据中自动学习和改进，从而实现自动识别、分类、预测和决策等任务。简单来说，机器学习是指通过观察大量历...
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 733.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:57,384 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:57,384 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 中等分散访问 | 活跃用户: 8个 | 每用户session: 2 | 请求间隔: 150ms | 进度: 13/80
2025-08-11 09:51:58,222 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_013] 命中: 685.97ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #14 ===
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_013 | 用户: user_001
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是过拟合？
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 在机器学习和深度学习中，过拟合（Overfitting）是指模型在训练数据上表现良好，但在测试数据上的性能下降的现象。换句话说，过拟合是指模型在训练数据集上过度...
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 686.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:51:58,223 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:51:58,376 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY计算: 目标命中率=0.85, 估算大小=2, 实际大小=5, 统计=Stats{总访问=15, 唯一键=3, Bucket数=200}
2025-08-11 09:52:00,053 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_014] 未命中: 1624.7ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=70)
2025-08-11 09:52:00,053 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #15 ===
2025-08-11 09:52:00,054 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_014 | 用户: user_005
2025-08-11 09:52:00,054 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:52:00,054 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型质量通常涉及以下几个方面：

1. 模型准确性：通过比较训练集和测试集上的预测结果，可以计算模型的准确率、精确率、召回率、F1分数等指标。这些指标反映了...
2025-08-11 09:52:00,054 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1624.7ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:00,054 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:00,055 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 15 | 成功: 15 (100.0%) | 平均耗时: 1050.3ms
2025-08-11 09:52:00,055 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:02,203 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_015] 未命中: 1944.54ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=68)
2025-08-11 09:52:02,204 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #16 ===
2025-08-11 09:52:02,204 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_015 | 用户: user_004
2025-08-11 09:52:02,204 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是迁移学习？
2025-08-11 09:52:02,204 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 迁移学习（Transfer Learning，TL）是一种机器学习技术，它利用已有的知识和经验来解决新的、复杂的问题。与传统的基于训练数据的机器学习方法不同，迁...
2025-08-11 09:52:02,205 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1944.5ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:02,205 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:02,984 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_016] 命中: 627.85ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #17 ===
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_016 | 用户: user_001
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种基于人工神经元和连接器的计算机模型，它能够从数据中学习模式，并根据这些模式做出预测或决策。神经网络的工作过程可以分为以下几个步骤：

1. 数据预...
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 627.9ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:02,985 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:05,003 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_017] 未命中: 1815.28ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=79)
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #18 ===
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_017 | 用户: user_008
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人脑神经元功能的计算模型，它能够从输入数据中学习特征，并通过多层非线性变换来预测输出结果。以下是神经网络的基本工作原理：

1. 数据预处理：...
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1815.3ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:05,004 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:05,992 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_018] 命中: 835.26ms (策略=FREQUENCY, 缓存大小=5, KV大小=79)
2025-08-11 09:52:05,992 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #19 ===
2025-08-11 09:52:05,992 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_018 | 用户: user_008
2025-08-11 09:52:05,992 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:05,992 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，它使用多层神经网络（ANN）来模拟人脑的高级认知过程。其基本原理包括以下步骤：

1. 数据准备：首先，数据集被划分为训练集和测试集...
2025-08-11 09:52:05,993 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 835.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:05,993 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:06,656 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_019] 命中: 510.78ms (策略=FREQUENCY, 缓存大小=5, KV大小=70)
2025-08-11 09:52:06,656 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #20 ===
2025-08-11 09:52:06,656 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_019 | 用户: user_005
2025-08-11 09:52:06,656 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:06,656 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它通过构建模型和算法，使计算机能够自动从数据中提取规律和模式，并根据这些规律和模式进行预测和决策。在机器学习中，算法通常被分为监督学...
2025-08-11 09:52:06,656 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 510.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:06,657 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:06,657 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 20 | 成功: 20 (100.0%) | 平均耗时: 1074.4ms
2025-08-11 09:52:06,657 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:07,550 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_020] 命中: 740.8ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:07,550 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #21 ===
2025-08-11 09:52:07,550 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_020 | 用户: user_001
2025-08-11 09:52:07,550 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:07,550 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，它是基于自注意力机制的神经网络，主要用于自然语言处理任务，例如文本生成、机器翻译、问答系统等。以下是Transform...
2025-08-11 09:52:07,551 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 740.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:07,551 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:08,618 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_021] 命中: 915.26ms (策略=FREQUENCY, 缓存大小=5, KV大小=79)
2025-08-11 09:52:08,618 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #22 ===
2025-08-11 09:52:08,618 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_021 | 用户: user_008
2025-08-11 09:52:08,618 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:08,619 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能的分支，它通过从数据中自动发现模式、规律和趋势来构建算法模型。简单来说，机器学习就是让计算机系统能够自动从经验中提取知识，并根据这些知识进...
2025-08-11 09:52:08,619 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 915.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:08,619 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:09,733 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_022] 命中: 962.58ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #23 ===
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_022 | 用户: user_002
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，它是由两个主要部分组成：编码器（Encoder）和解码器（Decoder）。这两个部分的主要工作原理如下：

1. *...
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 962.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:09,734 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:10,882 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_023] 命中: 995.64ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #24 ===
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_023 | 用户: user_002
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型质量通常涉及以下几个步骤：

1. **数据集准备**：首先，需要收集足够的高质量数据以训练和测试模型。这包括清理、标记和标注数据集，以便模型可以学习到...
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 995.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:10,883 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:11,673 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_024] 命中: 638.29ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:11,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #25 ===
2025-08-11 09:52:11,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_024 | 用户: user_001
2025-08-11 09:52:11,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是迁移学习？
2025-08-11 09:52:11,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 迁移学习（Transfer Learning，TL）是一种机器学习技术，它利用已经训练好的模型在新的任务上进行预测或分类，而不必重新训练整个模型。这种方法基于以...
2025-08-11 09:52:11,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 638.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:11,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:11,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 25 | 成功: 25 (100.0%) | 平均耗时: 1029.7ms
2025-08-11 09:52:11,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:11,675 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 中等分散访问 | 活跃用户: 8个 | 每用户session: 2 | 请求间隔: 150ms | 进度: 25/80
2025-08-11 09:52:12,691 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_025] 命中: 864.52ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:12,692 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #26 ===
2025-08-11 09:52:12,692 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_025 | 用户: user_002
2025-08-11 09:52:12,692 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:12,692 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是指能够理解和生成人类语言的计算机程序或算法。它们通常使用深度学习技术，如神经网络和循环神经网络（RNNs），以及大量的语料库和数据集来训练模型，...
2025-08-11 09:52:12,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 864.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:12,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:14,598 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_026] 未命中: 1702.3899999999999ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=79)
2025-08-11 09:52:14,598 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #27 ===
2025-08-11 09:52:14,598 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_026 | 用户: user_006
2025-08-11 09:52:14,598 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:14,599 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习方法，其基本原理是通过多层神经网络模拟人类大脑的结构和功能，从而实现对数据的学习和预测。深度学习的核心概念包括：

1. 层次化：深度学习...
2025-08-11 09:52:14,599 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1702.4ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:14,599 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:15,313 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_027] 命中: 512.45ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #28 ===
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_027 | 用户: user_004
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它使用算法和统计模型来使计算机系统从数据中自动学习模式，以便它们能够根据输入的数据做出预测或决策。这些模型可以是监督的（例如，分类、...
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 512.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:15,314 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:17,168 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_028] 未命中: 1651.01ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=103)
2025-08-11 09:52:17,168 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #29 ===
2025-08-11 09:52:17,168 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_028 | 用户: user_010
2025-08-11 09:52:17,168 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:17,168 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，主要用于处理序列数据，例如文本、音频和视频。它的核心组件是自注意力机制（Attention Mechanism），这是...
2025-08-11 09:52:17,169 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1651.0ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:17,169 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:17,320 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY计算: 目标命中率=0.85, 估算大小=5, 实际大小=5, 统计=Stats{总访问=30, 唯一键=8, Bucket数=200}
2025-08-11 09:52:18,905 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_029] 未命中: 1533.1399999999999ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=113)
2025-08-11 09:52:18,905 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #30 ===
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_029 | 用户: user_018
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，其基本原理是模仿人脑神经网络的结构和功能，通过多层非线性变换来自动提取特征，并使用这些特征进行模式识别、分类、回归等任务。以下是一些...
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1533.1ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 30 | 成功: 30 (100.0%) | 平均耗时: 1066.8ms
2025-08-11 09:52:18,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:20,960 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_030] 未命中: 1851.22ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=70)
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #31 ===
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_030 | 用户: user_003
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它让计算机通过从数据中学习和改进其性能，而无需明确编程。它的目标是使计算机能够自动识别模式、分类数据集，并根据这些模式进行预测或决策...
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1851.2ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:20,960 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:21,879 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_031] 命中: 767.16ms (策略=FREQUENCY, 缓存大小=5, KV大小=70)
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #32 ===
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_031 | 用户: user_003
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它让计算机从数据中自动学习模式和规律，并根据这些模式和规律来解决问题或完成任务。简单来说，机器学习是一种通过算法使计算机从经验中提取...
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 767.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:21,880 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:22,889 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_032] 命中: 807.08ms (策略=FREQUENCY, 缓存大小=5, KV大小=70)
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #33 ===
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_032 | 用户: user_005
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，由Google在2017年提出，它被广泛应用于自然语言处理任务中，例如文本生成、机器翻译和问答系统等。以下是对Tran...
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 807.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:22,890 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:23,787 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_033] 命中: 744.42ms (策略=FREQUENCY, 缓存大小=5, KV大小=113)
2025-08-11 09:52:23,787 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #34 ===
2025-08-11 09:52:23,787 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_033 | 用户: user_018
2025-08-11 09:52:23,787 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:52:23,787 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制是一种计算机视觉系统的设计，它允许计算机系统在处理图像或视频数据时，将焦点集中在一个特定的物体或者区域上。该机制主要通过以下步骤来实现：

1. **...
2025-08-11 09:52:23,787 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 744.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:23,788 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:25,843 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_034] 未命中: 1853.46ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=80)
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #35 ===
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_034 | 用户: user_009
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，由Google在2017年提出，主要用于自然语言处理任务，如文本生成、机器翻译和问答系统等。Transformer的主...
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1853.5ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:25,844 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 35 | 成功: 35 (100.0%) | 平均耗时: 1086.5ms
2025-08-11 09:52:25,845 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:27,566 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_035] 未命中: 1519.01ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=103)
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #36 ===
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_035 | 用户: user_014
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: "大语言模型"是指能够通过深度学习技术，从大量的文本数据中自动学习和提取信息的计算机程序。它是一种人工智能技术，可以模拟人类自然语言处理能力，包括理解和生成自然...
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1519.0ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:27,567 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:29,502 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_036] 未命中: 1732.01ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=103)
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #37 ===
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_036 | 用户: user_011
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是一种人工智能技术，它能够模拟人类的自然语言处理能力，包括理解和生成人类语言的能力。这种技术通常使用深度学习算法，特别是神经网络和循环神经网络（R...
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1732.0ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:29,502 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:29,502 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 高度分散访问 | 活跃用户: 25个 | 每用户session: 3 | 请求间隔: 150ms | 进度: 37/80
2025-08-11 09:52:31,745 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_037] 未命中: 2039.41ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=36)
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #38 ===
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_037 | 用户: user_021
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是过拟合？
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 过拟合（Overfitting）是指机器学习模型在训练集上表现良好，但在测试集上的表现较差的现象。这通常发生在模型过于复杂或训练数据不足的情况下。当模型过度拟合...
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 2039.4ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:31,745 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:32,893 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_038] 命中: 944.95ms (策略=FREQUENCY, 缓存大小=5, KV大小=79)
2025-08-11 09:52:32,893 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #39 ===
2025-08-11 09:52:32,893 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_038 | 用户: user_008
2025-08-11 09:52:32,893 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:52:32,893 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制（Attention Mechanism）是一种计算机视觉和自然语言处理领域的算法，用于在多任务处理中有效地提取、跟踪和整合输入数据中的关键信息。它主...
2025-08-11 09:52:32,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 945.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:32,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:35,064 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_039] 未命中: 1968.44ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=104)
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #40 ===
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_039 | 用户: user_013
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它使用算法和统计模型从数据中自动提取规律，从而实现计算机系统自动完成特定任务的能力。它的目标是让计算机系统通过分析大量数据，从中学习...
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1968.4ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 40 | 成功: 40 (100.0%) | 平均耗时: 1155.8ms
2025-08-11 09:52:35,065 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:35,995 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_040] 命中: 728.12ms (策略=FREQUENCY, 缓存大小=5, KV大小=68)
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #41 ===
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_040 | 用户: user_002
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人脑神经元结构和功能的计算模型，它由一系列互相连接的节点（也称为“神经元”）组成，这些节点接收输入信号并产生输出信号。以下是神经网络的基本工作...
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 728.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:35,996 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:37,894 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_041] 未命中: 1695.22ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=69)
2025-08-11 09:52:37,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #42 ===
2025-08-11 09:52:37,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_041 | 用户: user_007
2025-08-11 09:52:37,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:37,894 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 大语言模型（Large Language Model，简称LLM）是一种人工智能技术，它能够理解和生成人类自然语言，包括文本、语音和图像。LLM是一种深度学习模...
2025-08-11 09:52:37,895 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1695.2ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:37,895 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:38,693 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_042] 命中: 646.02ms (策略=FREQUENCY, 缓存大小=5, KV大小=104)
2025-08-11 09:52:38,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #43 ===
2025-08-11 09:52:38,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_042 | 用户: user_013
2025-08-11 09:52:38,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:38,693 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer（变换器）是一种深度学习模型，用于自然语言处理任务，如机器翻译、文本生成和问答系统等。它的主要思想是通过多层自注意力机制来捕捉输入序列中不...
2025-08-11 09:52:38,694 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 646.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:38,694 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:40,497 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_043] 未命中: 1600.4ms (+1000ms) (策略=FREQUENCY, 缓存大小=5, 新KV大小=37)
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #44 ===
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_043 | 用户: user_022
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型的质量通常涉及以下几个方面：

1. 模型准确性：这是最基础的评估指标，可以通过比较预测结果与真实标签之间的差异来衡量。例如，可以使用准确率、召回率、F...
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1600.4ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:40,498 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:40,649 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY计算: 目标命中率=0.85, 估算大小=11, 实际大小=11, 统计=Stats{总访问=45, 唯一键=17, Bucket数=200}
2025-08-11 09:52:40,649 INFO  com.infertuner.cache.TwoLevelCacheManager                    [] - 调整本地缓存大小: 5 -> 11
2025-08-11 09:52:40,650 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 缓存大小调整完成: 5 → 11 (CacheStats{总请求=44, 本地命中=24(54.5%), 远端命中=4(9.1%), 未命中=16(36.4%), 本地大小=5/11, 远端大小=16})
2025-08-11 09:52:42,633 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_044] 未命中: 1930.5ms (+1000ms) (策略=FREQUENCY, 缓存大小=11, 新KV大小=115)
2025-08-11 09:52:42,633 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #45 ===
2025-08-11 09:52:42,633 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_044 | 用户: user_017
2025-08-11 09:52:42,633 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:52:42,633 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer（变换器）是一种深度学习模型，它在自然语言处理（NLP）领域中被广泛应用于文本生成、机器翻译、问答系统、情感分析和文本摘要等领域。以下是T...
2025-08-11 09:52:42,634 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1930.5ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:42,634 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:42,634 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 45 | 成功: 45 (100.0%) | 平均耗时: 1174.1ms
2025-08-11 09:52:42,634 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:43,402 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_045] 命中: 616.36ms (策略=FREQUENCY, 缓存大小=11, KV大小=79)
2025-08-11 09:52:43,402 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #46 ===
2025-08-11 09:52:43,402 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_045 | 用户: user_006
2025-08-11 09:52:43,402 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:43,402 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，它使用多层神经网络来模仿人脑的神经元结构，以解决复杂的问题。它的基本原理可以概括为以下几点：

1. 建立模型：深度学习模型由多个层...
2025-08-11 09:52:43,402 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 616.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:43,403 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:44,513 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_046] 命中: 959.07ms (策略=FREQUENCY, 缓存大小=11, KV大小=70)
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #47 ===
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_046 | 用户: user_005
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它允许计算机从数据中自动学习和改进算法，从而实现对未知输入的预测或决策。在机器学习中，计算机通过分析、理解和利用大量已有的数据，从中...
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 959.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:44,514 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:45,592 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_047] 命中: 926.63ms (策略=FREQUENCY, 缓存大小=11, KV大小=68)
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #48 ===
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_047 | 用户: user_001
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿生物神经系统结构和功能的计算机模型，它由大量节点（称为“神经元”或“节点体”）组成，这些节点通过连接进行信息传递。以下是神经网络工作的基本步骤...
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 926.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:45,593 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:47,559 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_048] 未命中: 1813.69ms (+1000ms) (策略=FREQUENCY, 缓存大小=11, 新KV大小=37)
2025-08-11 09:52:47,559 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #49 ===
2025-08-11 09:52:47,559 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_048 | 用户: user_027
2025-08-11 09:52:47,559 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是机器学习？
2025-08-11 09:52:47,559 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 机器学习是一种人工智能技术，它使用算法和统计模型来让计算机从数据中自动学习并改进性能。机器学习的基本目标是构建一个模型，该模型可以从已有的数据中学习规律，并根据...
2025-08-11 09:52:47,559 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1813.7ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:47,560 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:47,560 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 混乱访问模式 | 活跃用户: 40个 | 每用户session: 随机1-5 | 请求间隔: 100ms | 进度: 49/80
2025-08-11 09:52:48,529 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_049] 命中: 867.32ms (策略=FREQUENCY, 缓存大小=11, KV大小=115)
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #50 ===
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_049 | 用户: user_017
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，它的基本原理是模拟人脑神经网络的工作方式，通过多层次的多层非线性变换，从原始数据中提取出高层次特征，从而实现对复杂问题的自动解决。其...
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 867.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 50 | 成功: 50 (100.0%) | 平均耗时: 1160.3ms
2025-08-11 09:52:48,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:49,542 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_050] 命中: 911.35ms (策略=FREQUENCY, 缓存大小=11, KV大小=68)
2025-08-11 09:52:49,542 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #51 ===
2025-08-11 09:52:49,543 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_050 | 用户: user_001
2025-08-11 09:52:49,543 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:52:49,543 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种基于人工神经元的计算机模型，它通过模拟人脑神经元之间的信息传递和学习过程，实现对数据的自动分析和处理。以下是一个简化的神经网络工作的步骤：

1....
2025-08-11 09:52:49,543 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 911.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:49,543 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:50,529 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_051] 命中: 884.58ms (策略=FREQUENCY, 缓存大小=11, KV大小=68)
2025-08-11 09:52:50,529 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #52 ===
2025-08-11 09:52:50,530 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_051 | 用户: user_001
2025-08-11 09:52:50,530 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:52:50,530 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制（Attention Mechanism）是机器学习和深度学习领域中的一种关键算法，它用于在多任务学习、强化学习和图像处理等场景中提取出最相关的信息并...
2025-08-11 09:52:50,530 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 884.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:50,530 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:51,613 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_052] 命中: 982.01ms (策略=FREQUENCY, 缓存大小=11, KV大小=104)
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #53 ===
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_052 | 用户: user_013
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何优化模型性能？
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 为了优化模型性能，可以采用以下几种方法：

1. 数据预处理：对数据进行清洗、归一化和标准化，以提高模型的训练效果。例如，可以使用特征缩放或归一化函数将不同尺度...
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 982.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:51,614 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:52,604 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_053] 命中: 838.41ms (策略=FREQUENCY, 缓存大小=11, KV大小=80)
2025-08-11 09:52:52,604 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #54 ===
2025-08-11 09:52:52,605 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_053 | 用户: user_009
2025-08-11 09:52:52,605 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是过拟合？
2025-08-11 09:52:52,605 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 过拟合（Overfitting）是指机器学习模型在训练数据集上表现良好，但在测试数据集上表现不佳的现象。这是因为模型过于复杂，以至于它能够很好地捕捉到训练数据中...
2025-08-11 09:52:52,605 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 838.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:52,605 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:54,384 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_054] 未命中: 1627.1399999999999ms (+1000ms) (策略=FREQUENCY, 缓存大小=11, 新KV大小=68)
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #55 ===
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_054 | 用户: user_033
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，其基本原理是模拟人脑神经元的工作方式，通过多层人工神经网络从数据中提取特征并进行分类、回归或聚类等任务。以下是深度学习的基本原理：
...
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1627.1ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 55 | 成功: 55 (100.0%) | 平均耗时: 1150.2ms
2025-08-11 09:52:54,385 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:56,196 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_055] 未命中: 1659.1ms (+1000ms) (策略=FREQUENCY, 缓存大小=11, 新KV大小=91)
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #56 ===
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_055 | 用户: user_040
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是指能够理解和生成人类自然语言的计算机程序，它可以通过大量的数据和复杂的算法来模拟人类的思维过程，并从中学习和改进。这些模型通常由深度神经网络（D...
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1659.1ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:56,197 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:56,913 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_056] 命中: 614.21ms (策略=FREQUENCY, 缓存大小=11, KV大小=104)
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #57 ===
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_056 | 用户: user_013
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: “大语言模型”是一种基于深度学习的计算机程序，它可以模拟人类的语言理解和生成能力。它通过使用大量的语料库和算法来训练神经网络，使模型能够理解自然语言的语法、词汇...
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 614.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:56,913 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:58,986 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_057] 未命中: 1920.87ms (+1000ms) (策略=FREQUENCY, 缓存大小=11, 新KV大小=104)
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #58 ===
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_057 | 用户: user_012
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型质量通常包括以下几个步骤：

1. 数据准备：首先，需要对数据集进行清洗和预处理。这可能包括去除缺失值、异常值或不一致性，以及标准化或归一化数据以确保所...
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 1920.9ms | 模型: Qwen1.5-1.8B-Chat-Miss
2025-08-11 09:52:58,987 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:59,601 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_058] 命中: 512.02ms (策略=FREQUENCY, 缓存大小=11, KV大小=37)
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #59 ===
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_058 | 用户: user_022
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是过拟合？
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 过拟合（Overfitting）是指模型在训练集上表现良好，但在测试集或新数据上的表现较差的现象。它通常发生在机器学习模型中，特别是那些使用了复杂模型结构、过度...
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 512.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:52:59,601 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:52:59,702 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY计算: 目标命中率=0.85, 估算大小=13, 实际大小=13, 统计=Stats{总访问=60, 唯一键=21, Bucket数=200}
2025-08-11 09:52:59,702 INFO  com.infertuner.cache.TwoLevelCacheManager                    [] - 调整本地缓存大小: 11 -> 13
2025-08-11 09:52:59,702 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 缓存大小调整完成: 11 → 13 (CacheStats{总请求=59, 本地命中=30(50.8%), 远端命中=8(13.6%), 未命中=21(35.6%), 本地大小=11/13, 远端大小=21})
2025-08-11 09:53:00,621 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_059] 命中: 867.18ms (策略=FREQUENCY, 缓存大小=13, KV大小=103)
2025-08-11 09:53:00,621 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #60 ===
2025-08-11 09:53:00,621 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_059 | 用户: user_011
2025-08-11 09:53:00,621 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:53:00,621 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人脑神经元运作方式的计算模型，它通过一系列多层非线性变换和激活函数来学习数据特征并进行分类、回归、聚类等任务。神经网络的工作过程可以分为以下几...
2025-08-11 09:53:00,621 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 867.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:00,622 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:53:00,622 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 60 | 成功: 60 (100.0%) | 平均耗时: 1147.2ms
2025-08-11 09:53:00,622 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:01,649 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_060] 命中: 875.71ms (策略=FREQUENCY, 缓存大小=13, KV大小=70)
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #61 ===
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_060 | 用户: user_003
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 大语言模型（Big Language Model，简称BLM）是一种计算机程序或系统，它能够理解和生成自然语言文本。BLM通常用于处理和生成复杂的、具有上下文关...
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 875.7ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:01,650 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:01,650 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 回归集中访问 | 活跃用户: 5个 | 每用户session: 1 | 请求间隔: 100ms | 进度: 61/80
2025-08-11 09:53:02,747 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_061] 命中: 996.2ms (策略=FREQUENCY, 缓存大小=13, KV大小=70)
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #62 ===
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_061 | 用户: user_003
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何优化模型性能？
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 优化模型性能可以从多个方面进行，以下是一些常用的方法：

1. 数据预处理：数据预处理包括清洗、归一化、标准化等步骤。这些步骤可以帮助提高模型的训练效率和预测准...
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 996.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:02,748 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:03,754 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_062] 命中: 853.78ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #63 ===
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_062 | 用户: user_002
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer是一种深度学习模型，主要用于自然语言处理任务，例如机器翻译、文本摘要、问答系统和文本生成等。它的核心思想是通过自注意力机制和编码-解码机制...
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 853.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:03,754 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:04,691 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_063] 命中: 784.51ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #64 ===
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_063 | 用户: user_004
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习方法，其基本原理是基于多层神经网络（NN），这些神经网络由多个层次组成，每个层次都有一个或多个隐藏层。每一层都包含大量的神经元，它们通过一...
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 784.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:04,691 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:05,428 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_064] 命中: 635.77ms (策略=FREQUENCY, 缓存大小=13, KV大小=70)
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #65 ===
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_064 | 用户: user_003
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估模型质量通常涉及以下几个方面：

1. 准确性：这是评估模型性能最基本的标准之一。准确性是指模型预测结果与实际结果之间的差异程度，通常用准确率、召回率和F1...
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 635.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 65 | 成功: 65 (100.0%) | 平均耗时: 1122.7ms
2025-08-11 09:53:05,429 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:06,163 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_065] 命中: 631.99ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #66 ===
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_065 | 用户: user_002
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制是一种机器学习算法，用于处理和理解复杂的数据集，以确定哪些输入对输出产生最大的影响。它通常应用于计算机视觉、自然语言处理（NLP）、语音识别和推荐系统...
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 632.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:06,163 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:07,009 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_066] 命中: 744.51ms (策略=FREQUENCY, 缓存大小=13, KV大小=70)
2025-08-11 09:53:07,009 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #67 ===
2025-08-11 09:53:07,010 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_066 | 用户: user_003
2025-08-11 09:53:07,010 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:53:07,010 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿生物大脑运作方式的计算模型，它由大量相互连接的节点（也称为“神经元”）组成。这些节点通过权重和偏差来接收输入数据，并根据它们之间的关系产生输出...
2025-08-11 09:53:07,010 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 744.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:07,010 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:07,895 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_067] 命中: 783.79ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:07,895 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #68 ===
2025-08-11 09:53:07,895 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_067 | 用户: user_002
2025-08-11 09:53:07,895 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:53:07,896 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 大语言模型（Deep Learning Model）是一种使用深度学习技术构建的自然语言处理系统，旨在模拟人类的自然语言理解和生成能力。这种模型通常包含多个层次...
2025-08-11 09:53:07,896 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 783.8ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:07,896 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:08,646 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_068] 命中: 649.05ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #69 ===
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_068 | 用户: user_004
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，其基本原理基于神经网络的结构和训练过程。以下是一些主要的深度学习基础概念：

1. 神经网络：神经网络是一种由多层相互连接的节点组成...
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 649.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:08,647 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:09,368 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_069] 命中: 619.91ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #70 ===
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_069 | 用户: user_001
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 如何评估模型质量？
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 评估一个机器学习模型的质量通常需要考虑以下几个方面：

1. 准确性：准确性是衡量模型性能的一个关键指标，它通常使用准确率、精确率、召回率和F1分数等统计量来计...
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 619.9ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 70 | 成功: 70 (100.0%) | 平均耗时: 1091.5ms
2025-08-11 09:53:09,369 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:10,007 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_070] 命中: 536.2ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #71 ===
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_070 | 用户: user_001
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 解释一下Transformer架构
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: Transformer（Transformers）是一种用于自然语言处理（NLP）任务的深度学习模型，由Facebook在2017年提出。它的主要特点是自注意力...
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 536.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:10,007 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:10,674 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_071] 命中: 565.38ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:10,674 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #72 ===
2025-08-11 09:53:10,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_071 | 用户: user_002
2025-08-11 09:53:10,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:53:10,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种模仿人类大脑结构和功能的计算模型，它由大量的输入数据（称为“神经元”）和一组隐藏层组成。以下是神经网络工作的一些主要步骤：

1. 输入处理：神经...
2025-08-11 09:53:10,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 565.4ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:10,675 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:11,409 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_072] 命中: 633.05ms (策略=FREQUENCY, 缓存大小=13, KV大小=70)
2025-08-11 09:53:11,409 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #73 ===
2025-08-11 09:53:11,409 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_072 | 用户: user_003
2025-08-11 09:53:11,410 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:53:11,410 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，其基本原理是通过构建多层神经网络来模拟人脑的神经元工作方式。这种模型通常由多个层次组成，每个层次都包含大量的节点（称为“隐藏层”），...
2025-08-11 09:53:11,410 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 633.1ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:11,410 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:11,410 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 负载阶段: 回归集中访问 | 活跃用户: 5个 | 每用户session: 1 | 请求间隔: 100ms | 进度: 73/80
2025-08-11 09:53:12,445 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_073] 命中: 934.01ms (策略=FREQUENCY, 缓存大小=13, KV大小=68)
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #74 ===
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_073 | 用户: user_001
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 深度学习的基本原理是什么？
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 深度学习是一种机器学习技术，它使用多层神经网络来模拟人类大脑的处理过程，从而实现对复杂数据进行分析和预测。以下是深度学习的基本原理：

1. 数据预处理：首先，...
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 934.0ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:12,446 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:12,547 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY计算: 目标命中率=0.85, 估算大小=12, 实际大小=12, 统计=Stats{总访问=75, 唯一键=21, Bucket数=200}
2025-08-11 09:53:12,547 INFO  com.infertuner.cache.TwoLevelCacheManager                    [] - 调整本地缓存大小: 13 -> 12
2025-08-11 09:53:12,547 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 缓存大小调整完成: 13 → 12 (CacheStats{总请求=74, 本地命中=41(55.4%), 远端命中=12(16.2%), 未命中=21(28.4%), 本地大小=12/12, 远端大小=21})
2025-08-11 09:53:13,407 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_074] 命中: 858.32ms (策略=FREQUENCY, 缓存大小=12, KV大小=68)
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #75 ===
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_074 | 用户: user_002
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是迁移学习？
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 迁移学习（Transfer Learning，简称TL）是一种机器学习技术，它利用已有的知识和经验来解决新的任务或问题。它主要通过将一个模型的结构和参数应用于另...
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 858.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 75 | 成功: 75 (100.0%) | 平均耗时: 1065.8ms
2025-08-11 09:53:13,407 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:14,226 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_075] 命中: 717.22ms (策略=FREQUENCY, 缓存大小=12, KV大小=70)
2025-08-11 09:53:14,226 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #76 ===
2025-08-11 09:53:14,226 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_075 | 用户: user_003
2025-08-11 09:53:14,226 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:53:14,226 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制是机器学习中的一种技术，用于处理输入数据并确定其中最有意义的信息。它通过分析输入数据的特征和上下文来确定哪些部分最相关，并将这些信息分配给相应的处理单...
2025-08-11 09:53:14,226 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 717.2ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:14,227 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:15,266 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_076] 命中: 937.85ms (策略=FREQUENCY, 缓存大小=12, KV大小=70)
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #77 ===
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_076 | 用户: user_003
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制是一种机器学习技术，它用于处理和理解输入数据中的注意力信息。在计算机视觉、自然语言处理、语音识别等领域中，注意力机制通常被用来提升模型的性能，特别是在...
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 937.9ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:15,266 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:16,007 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_077] 命中: 639.6ms (策略=FREQUENCY, 缓存大小=12, KV大小=68)
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #78 ===
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_077 | 用户: user_002
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 神经网络如何工作？
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 神经网络是一种基于人工神经元的计算模型，其基本工作原理是通过模拟人脑中的神经元之间的连接来实现信息处理和模式识别。神经网络由输入层、隐藏层和输出层组成，每个层次...
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 639.6ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:16,008 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:17,077 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_078] 命中: 967.5ms (策略=FREQUENCY, 缓存大小=12, KV大小=68)
2025-08-11 09:53:17,077 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #79 ===
2025-08-11 09:53:17,077 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_078 | 用户: user_004
2025-08-11 09:53:17,077 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是注意力机制？
2025-08-11 09:53:17,077 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 注意力机制是一种计算机视觉系统算法，用于处理图像中的物体和场景。它通过学习输入图像中物体的位置、形状、大小以及与周围环境的关系，来确定最相关的对象，并在当前时刻...
2025-08-11 09:53:17,078 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 967.5ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:17,078 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:17,905 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - [req_079] 命中: 726.26ms (策略=FREQUENCY, 缓存大小=12, KV大小=70)
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - === 结果 #80 ===
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 请求ID: req_079 | 用户: user_003
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 问题: 什么是大语言模型？
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 回答: 大语言模型（Large Language Model，简称LLM）是一种能够理解和生成人类自然语言的计算机程序。它通常被用来处理文本、语音或视频数据，并通过深度...
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 状态: 成功 | 耗时: 726.3ms | 模型: Qwen1.5-1.8B-Chat-Hit
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - --- 统计 ---
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - 总数: 80 | 成功: 80 (100.0%) | 平均耗时: 1049.0ms
2025-08-11 09:53:17,906 INFO  com.infertuner.sinks.SimpleResultSink                        [] - ================
2025-08-11 09:53:17,906 INFO  com.infertuner.sources.CacheAwareRequestSource               [] - 优化负载请求流生成完成，共 80 个请求
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - === 最终统计 (策略: FREQUENCY) ===
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 总请求: 80
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 缓存命中: 59 (73.8%)
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 平均延迟: 1049.0ms
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 最终缓存大小: 12
2025-08-11 09:53:22,341 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 二级缓存统计: CacheStats{总请求=80, 本地命中=47(58.8%), 远端命中=12(15.0%), 未命中=21(26.2%), 本地大小=12/12, 远端大小=21}
2025-08-11 09:53:22,342 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - FREQUENCY策略统计: Stats{总访问=80, 唯一键=21, Bucket数=200}
2025-08-11 09:53:22,342 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - ================
2025-08-11 09:53:22,345 INFO  com.infertuner.processors.CacheEnabledInferenceProcessor     [] - 模块化缓存推理服务已关闭
2025-08-11 09:53:22,348 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FINISHED.
2025-08-11 09:53:22,348 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 (3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2025-08-11 09:53:22,351 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: Cache-Aware Request Source -> Cache-Enabled Inference Processor -> Sink: Result Sink (1/1)#0 3591a9cf2e0f084d89ce97b30343a878_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2025-08-11 09:53:22,418 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=364.800mb (382520517 bytes), taskOffHeapMemory=0 bytes, managedMemory=343.040mb (359703515 bytes), networkMemory=85.760mb (89925878 bytes)}, allocationId: 9a6f81c900ef241ce19998b167ef2d71, jobId: 77bcb6f409e6d90ca30dbd473ecf2d2c).
2025-08-11 09:53:22,420 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 77bcb6f409e6d90ca30dbd473ecf2d2c from job leader monitoring.
2025-08-11 09:53:22,421 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 77bcb6f409e6d90ca30dbd473ecf2d2c.
