package com.infertuner.processors;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.infertuner.models.InferenceRequest;
import com.infertuner.models.InferenceResponse;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.ProcessFunction;
import org.apache.flink.util.Collector;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.*;
import java.net.UnknownHostException;
import java.util.*;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.ConcurrentLinkedQueue;

/**
 * æ‰¹å¤„ç†å™¨ - ä¸ä½¿ç”¨Flink Stateï¼Œé¿å…keyByé—®é¢˜
 * ä½¿ç”¨å†…å­˜ç¼“å†²å®ç°æ”’æ‰¹åŠŸèƒ½
 */
public class ParallelBatchProcessor extends ProcessFunction<InferenceRequest, InferenceResponse> {

    private static final Logger logger = LoggerFactory.getLogger(ParallelBatchProcessor.class);

    // GPUç›¸å…³
    private int gpuId;
    private String nodeIP;
    private int taskIndex;
    private int totalParallelism;
    private transient Process inferenceProcess;  // æ ‡è®°ä¸ºtransient
    private transient BufferedWriter processInput;  // æ ‡è®°ä¸ºtransient
    private transient BufferedReader processOutput;  // æ ‡è®°ä¸ºtransient
    private transient ObjectMapper objectMapper;  // æ ‡è®°ä¸ºtransient

    // æ”’æ‰¹é…ç½®
    private int targetBatchSize = 4;

    // å†…å­˜ç¼“å†²åŒº- åœ¨open()ä¸­åˆå§‹åŒ–
    private transient Queue<InferenceRequest> requestBuffer;
    private transient Queue<Long> arrivalTimes;
    private transient long currentBatchFirstRequestTime = 0;
    private transient int batchCounter = 0;

    // private static final String MODEL_NAME = "Qwen3-30B-A3B-Instruct";
    private static final String MODEL_NAME = "Falcon3-7B-Instruct";
    private static final String MODEL_PATH = "/mnt/tidal-alsh01/usr/suqian/models/".concat(MODEL_NAME);
    private static final String BATCH_SERVICE_SCRIPT = "/mnt/tidal-alsh01/usr/suqian/scripts/batch_inference_service_new.py";

    @Override
    public void open(Configuration parameters) throws Exception {
        super.open(parameters);

        // åˆå§‹åŒ–transientå­—æ®µ
        requestBuffer = new ConcurrentLinkedQueue<>();
        arrivalTimes = new ConcurrentLinkedQueue<>();
        objectMapper = new ObjectMapper();

        taskIndex = getRuntimeContext().getIndexOfThisSubtask();
        totalParallelism = getRuntimeContext().getNumberOfParallelSubtasks();
        gpuId = 0;

        // è·å–çš„å½“å‰èŠ‚ç‚¹IP
        try {
            nodeIP = java.net.InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            logger.error("è·å–å½“å‰èŠ‚ç‚¹IPå¤±è´¥", e);
            nodeIP = "Unknown-hostIP";
        }

        // ä»å…¨å±€å‚æ•°è·å–é…ç½®
        try {
            Map<String, String> globalParams = getRuntimeContext().getExecutionConfig()
                    .getGlobalJobParameters().toMap();

            if (globalParams.containsKey("batch.size")) {
                targetBatchSize = Integer.parseInt(globalParams.get("batch.size"));
            }
        } catch (Exception e) {
            logger.warn("ä½¿ç”¨é»˜è®¤é…ç½®: batchSize={}", targetBatchSize);
        }

        logger.info("ğŸ¯ èŠ‚ç‚¹ {} ç®€åŒ–å¹¶è¡Œæ”’æ‰¹å¤„ç†å™¨å¯åŠ¨: å¹¶è¡Œåº¦={}, æ‰¹å¤§å°={}",
                nodeIP, totalParallelism, targetBatchSize);
        logger.info("ğŸ“‹ èŠ‚ç‚¹ {} è´Ÿè´£å¤„ç†: taskIndex={}, ä½¿ç”¨å†…å­˜ç¼“å†²åŒº", nodeIP, taskIndex);

        objectMapper.configure(com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);

        // å¯åŠ¨å†…è”æ¨ç†æœåŠ¡è¿›ç¨‹
        startGPUService();

        logger.info("âœ… èŠ‚ç‚¹ {} ç®€åŒ–å¹¶è¡Œæ”’æ‰¹æœåŠ¡å¯åŠ¨å®Œæˆ", nodeIP);
    }

    private void startGPUService() throws Exception {
        logger.info("å¯åŠ¨èŠ‚ç‚¹ {} æ¨ç†æœåŠ¡...", nodeIP);

        ProcessBuilder pb = new ProcessBuilder(
                "/opt/conda/envs/vllm-env/bin/python", BATCH_SERVICE_SCRIPT, nodeIP, MODEL_PATH, String.valueOf(gpuId));
        pb.redirectErrorStream(false);
        inferenceProcess = pb.start();

        processInput = new BufferedWriter(new OutputStreamWriter(inferenceProcess.getOutputStream()));
        processOutput = new BufferedReader(new InputStreamReader(inferenceProcess.getInputStream()));

        // ç­‰å¾…æœåŠ¡å¯åŠ¨
        logger.info("ç­‰å¾…èŠ‚ç‚¹ {} æœåŠ¡å¯åŠ¨...", nodeIP);
        Thread.sleep(3000);

        if (!inferenceProcess.isAlive()) {
            throw new RuntimeException("èŠ‚ç‚¹ " + nodeIP + " æ¨ç†æœåŠ¡å¯åŠ¨å¤±è´¥");
        }

        logger.info("âœ… èŠ‚ç‚¹ {} æ¨ç†æœåŠ¡å¯åŠ¨æˆåŠŸ", nodeIP);
    }

    @Override
    public void processElement(InferenceRequest request, Context ctx, Collector<InferenceResponse> out) throws Exception {
        // æ›´æ–°è¯·æ±‚çš„è¢«æ¥å—æ—¶é—´
        request.setAcceptedTimestamp(System.currentTimeMillis());

        // å°†è¯·æ±‚åŠ å…¥ç¼“å†²åŒº
        requestBuffer.offer(request);
        arrivalTimes.offer(request.getAcceptedTimestamp());

        int currentSize = requestBuffer.size();

        // è®°å½•æ‰¹æ¬¡ä¸­ç¬¬ä¸€ä¸ªè¯·æ±‚æ—¶é—´
        if (currentSize == 1) {
            currentBatchFirstRequestTime = request.getAcceptedTimestamp();
            logger.info("èŠ‚ç‚¹ {} å¼€å§‹ç¬¬ {} æ¬¡æ”’æ‰¹", nodeIP, batchCounter);
        } else {
            logger.info("èŠ‚ç‚¹ {} æ¥æ”¶åˆ°è¯·æ±‚ï¼Œå½“å‰è¯·æ±‚æ•°: {} / {}", nodeIP, currentSize, targetBatchSize);
        }

        if (currentSize >= targetBatchSize) {
            logger.info("ğŸš€ èŠ‚ç‚¹ {} æ”’å¤Ÿ {} ä¸ªè¯·æ±‚ï¼Œç¬¬ {} ä¸ªæ‰¹æ¬¡å¼€å§‹å¤„ç†", nodeIP, targetBatchSize, batchCounter);
            processBatch(out);
        }
    }

    private void processBatch(Collector<InferenceResponse> out) throws Exception {
        // æœ¬æ¬¡æ‰¹å¤„ç†çš„è¯·æ±‚é˜Ÿåˆ—
        List<InferenceRequest> requestBatch = new ArrayList<>();

        // ä»ç¼“å†²åŒºå–å‡ºtargetBatchSizeä¸ªè¯·æ±‚
        for (int i = 0; i < targetBatchSize; i++) {
            InferenceRequest req = requestBuffer.poll();
            if (req != null) {
                // æ›´æ–°è¯·æ±‚çš„å¼€å§‹å¤„ç†æ—¶é—´
                req.setProcessingTimestamp(System.currentTimeMillis());
                requestBatch.add(req);
            }
        }

        if (requestBatch.isEmpty()) {
            return;
        }

        int batchSize = requestBatch.size();
        // æ›´æ–°å½“å‰çš„æ‰¹æ¬¡æ•°
        int currentBatchNum = ++batchCounter;
        // å½“ä¸è€ƒè™‘è¶…æ—¶æœºåˆ¶æ—¶ï¼Œæ‰¹æ¬¡å†…æœ€åä¸€ä¸ªè¯·æ±‚çš„åˆ°è¾¾æ—¶é—´(è¢«æ¥å—æ—¶é—´)å³ä¸ºè¯¥æ‰¹æ¬¡çš„è§¦å‘æ—¶é—´
        long batchTriggerTime = requestBatch.get(targetBatchSize - 1).getAcceptedTimestamp();

        // æ„å»ºç”¨äºä¼ è¾“çš„æ‰¹æ¬¡è¯·æ±‚ä½“
        BatchRequestData batchRequest = new BatchRequestData();
        batchRequest.requests = new ArrayList<>();

        for (InferenceRequest req : requestBatch) {
            // æ„é€ å•æ¡è¯·æ±‚ä½“
            SingleRequestData singleReq = new SingleRequestData();
            singleReq.user_message = req.getUserMessage();
            singleReq.userId = req.getUserId();
            singleReq.max_tokens = req.getMaxTokens();
            singleReq.request_id = req.getRequestId();
            batchRequest.requests.add(singleReq);
        }

        batchRequest.batch_size = batchSize;
        batchRequest.batch_id = String.format("node-%s_batch_%d_%d", nodeIP, currentBatchNum, batchTriggerTime);

        // å°†è¯·æ±‚å‘é€åˆ° Python æ¨ç†è¿›ç¨‹
        String requestJson = objectMapper.writeValueAsString(batchRequest);
        processInput.write(requestJson + "\n");
        processInput.flush();

        long inferenceStartTime = System.currentTimeMillis();

        // ä» Python æ¨ç†è¿›ç¨‹è·å–å“åº”
        String responseJson = processOutput.readLine();
        if (responseJson == null) {
            throw new RuntimeException("èŠ‚ç‚¹ " + nodeIP + " æ— å“åº”");
        }

        // æ„é€ å“åº”ä½“ï¼Œè§£æ Python æ¨ç†æœåŠ¡çš„å“åº”å†…å®¹
        BatchResponseData batchResponse = objectMapper.readValue(responseJson, BatchResponseData.class);

        if (!batchResponse.success) {
            throw new RuntimeException("èŠ‚ç‚¹ " + nodeIP + " å¤„ç†å¤±è´¥: " + batchResponse.error);
        }

        long inferenceEndTime = System.currentTimeMillis();
        long inferenceTime = inferenceEndTime - inferenceStartTime;

        logger.info("ğŸ“Š èŠ‚ç‚¹ {} æ‰¹æ¬¡#{} å®Œæˆ: æ€»æ¨ç†æ—¶é—´={}ms",
                nodeIP, currentBatchNum, inferenceTime);

        // ä»å“åº”ä¸­è·å–æ•°æ®
        for (int i = 0; i < requestBatch.size(); i++) {
            InferenceRequest originalReq = requestBatch.get(i);
            SingleResponseData singleResp = batchResponse.responses.get(i);
            long requestArrivalTime = originalReq.getAcceptedTimestamp();

            InferenceResponse response = new InferenceResponse();
            response.requestId = originalReq.requestId;
            response.userId = originalReq.userId;
            response.userMessage = originalReq.userMessage;
            response.aiResponse = singleResp.response;
            response.inferenceTimeMs = inferenceTime;
            response.success = singleResp.success;
            response.modelName = String.format("node-%s", nodeIP);
            response.fromCache = false;
            response.batchSize = batchSize;
            response.timestamp = inferenceEndTime;
            response.setRequestAcceptedTime(originalReq.getAcceptedTimestamp());

            // ğŸ”§ æ‰¹æ¬¡è§¦å‘æ—¶é—´è®¡ç®—ç­‰å¾…æ—¶é—´
            // ç­‰å¾…æ—¶é—´ = æ‰¹æ¬¡è§¦å‘æ—¶é—´ - è¯·æ±‚åˆ°è¾¾æ—¶é—´
            long waitTime = batchTriggerTime - requestArrivalTime;

            response.waitTimeMs = waitTime;
            response.batchProcessTimeMs = inferenceTime;
            response.totalLatencyMs = waitTime + inferenceTime;

            logger.info("è¯·æ±‚ {} å¤„ç†å®Œæˆï¼Œç­‰å¾… {} æ¯«ç§’ï¼Œæ¨ç† {} æ¯«ç§’ï¼Œæ€»è€—æ—¶ {} æ¯«ç§’", response.requestId, response.waitTimeMs, response.inferenceTimeMs, response.totalLatencyMs);

            // è¾“å‡ºå“åº”
            out.collect(response);
        }

        logger.info("âœ… èŠ‚ç‚¹ {} æ‰¹æ¬¡#{} è¾“å‡º{}ä¸ªå“åº”", nodeIP, currentBatchNum, batchSize);
    }

    @Override
    public void close() throws Exception {
        logger.info("å…³é—­èŠ‚ç‚¹ {} æœåŠ¡...", nodeIP);

        try {
            if (processInput != null) {
                ShutdownCommand shutdownCmd = new ShutdownCommand();
                String shutdownJson = objectMapper.writeValueAsString(shutdownCmd);
                processInput.write(shutdownJson + "\n");
                processInput.flush();
                processInput.close();
            }

            if (processOutput != null) {
                processOutput.close();
            }

            if (inferenceProcess != null && inferenceProcess.isAlive()) {
                if (!inferenceProcess.waitFor(5, TimeUnit.SECONDS)) {
                    inferenceProcess.destroyForcibly();
                }
            }
        } catch (Exception e) {
            logger.error("å…³é—­èŠ‚ç‚¹ -{} æœåŠ¡å‡ºé”™: {}", nodeIP, e.getMessage());
        }

        logger.info("âœ… èŠ‚ç‚¹ -{} æœåŠ¡å·²å…³é—­", nodeIP);
        super.close();
    }

    // æ•°æ®ç»“æ„ç±»
    private static class BatchRequestData {
        public List<SingleRequestData> requests;
        public int batch_size;
        public String batch_id;
    }

    private static class SingleRequestData {
        public String userId;
        public String user_message;
        public int max_tokens;
        public String request_id;
    }

    private static class BatchResponseData {
        public List<SingleResponseData> responses;
        public int batch_size;
        public String batch_id;
        public long total_inference_time_ms;
        public boolean success;
        public String error;
        public long timestamp;
    }

    private static class SingleResponseData {
        public String response;
        public double inference_time_ms;
        public String request_id;
        public boolean success;
        public long timestamp;
    }

    private static class ShutdownCommand {
        public String command = "shutdown";
    }
}