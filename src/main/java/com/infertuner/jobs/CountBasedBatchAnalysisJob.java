package com.infertuner.jobs;

import com.infertuner.models.InferenceRequest;
import com.infertuner.models.InferenceResponse;
import com.infertuner.processors.KeyedProcessFunctionBatchProcessor;
import com.infertuner.sinks.UnifiedPerformanceSink;
import com.infertuner.sources.BasicRequestSource;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;

/**
 * åŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹åˆ†æä½œä¸š
 *
 * æ ¸å¿ƒç‰¹ç‚¹ï¼š
 * 1. çœŸæ­£çš„"æ”’å¤ŸNä¸ªè¯·æ±‚ç«‹å³å¤„ç†"è¯­ä¹‰
 * 2. ä½¿ç”¨ProcessFunction + Stateå®ç°å¯é çš„ç¼“å†²
 * 3. è¶…æ—¶ä¿æŠ¤æœºåˆ¶ï¼Œé¿å…æ­»é”
 * 4. ä¸€ä¸ªæ‰¹æ¬¡è¾“å‡ºå¤šä¸ªå“åº”ï¼Œå®Œç¾è§£å†³Windowé—®é¢˜
 */
public class CountBasedBatchAnalysisJob {

    private static final Logger logger = LoggerFactory.getLogger(CountBasedBatchAnalysisJob.class);

    public static void main(String[] args) throws Exception {
        logger.info("=== InferTuner åŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹éªŒè¯ ===");

        // è§£æå‚æ•°
        int batchSize = args.length > 0 ? Integer.parseInt(args[0]) : 4;
        int parallelism = args.length > 1 ? Integer.parseInt(args[1]) : 1;
        int maxRequests = args.length > 2 ? Integer.parseInt(args[2]) : 30;
        long interval = args.length > 3 ? Long.parseLong(args[3]) : 200;

        // ğŸ”§ è¶…æ—¶é…ç½®ï¼šç¡®ä¿ä¸ä¼šæ­»é”
        long maxWaitTimeMs = Math.max(batchSize * interval * 2, 2000);

        // é”®ç»„
        ArrayList<String> keyList = new ArrayList<>();
        for (int i = 0; i < parallelism; i++) {
            keyList.add("key" + i);
        }

        logger.info("ğŸ¯ åŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹é…ç½®:");
        logger.info("  ç›®æ ‡æ‰¹å¤§å°: {} (æ”’å¤Ÿç«‹å³å¤„ç†)", batchSize);
        logger.info("  å¹¶è¡Œåº¦: {}", parallelism);
        logger.info("  æ€»è¯·æ±‚æ•°: {}", maxRequests);
        logger.info("  è¯·æ±‚é—´éš”: {}ms", interval);
        logger.info("  è¶…æ—¶ä¿æŠ¤: {}ms (é¿å…æ­»é”)", maxWaitTimeMs);
        logger.info("  æ”’æ‰¹è¯­ä¹‰: æ•°é‡ä¼˜å…ˆ + æ—¶é—´å…œåº•");

        // åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(parallelism);

        // ğŸ”§ é…ç½®å…¨å±€å‚æ•°
        Configuration config = new Configuration();
        config.setString("batch.size", String.valueOf(batchSize));
        config.setString("max.wait.ms", String.valueOf(maxWaitTimeMs));
        config.setString("request.interval", String.valueOf(interval));
        config.setString("max.requests", String.valueOf(maxRequests));
        env.getConfig().setGlobalJobParameters(config);

        logger.info("âœ… å…¨å±€å‚æ•°é…ç½®å®Œæˆï¼Œç¡®ä¿ProcessFunctionè·å–æ­£ç¡®é…ç½®");
        logger.info("ğŸ” è¯·æ±‚æºé…ç½®éªŒè¯:");
        logger.info("  è¯·æ±‚é—´éš”: {}ms", interval);
        logger.info("  æ€»è¯·æ±‚æ•°: {}", maxRequests);
        logger.info("  é¢„æœŸæ€»æ—¶é•¿: çº¦{}ç§’", (maxRequests * interval) / 1000.0);

        // æ„å»ºåŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹æµæ°´çº¿
        DataStream<InferenceRequest> requests = env
                .addSource(new BasicRequestSource(maxRequests, interval)) // è®¾ç½®ä¸ºtrueï¼Œç­‰å¾…æ‰€æœ‰è¯·æ±‚å¤„ç†xå®Œæˆ
                .name("Count Batch Request Source");

        // ç”¨requestçš„requestIDä½œä¸ºé”®ï¼Œå¹¶ä¸”ä½¿ç”¨rebalance()è¿›è¡Œè´Ÿè½½å‡è¡¡
        // æ³¨ï¼šé€šè¿‡keyByè·å–keyåï¼Œflinkè¿˜ä¼šè¿›è¡Œkeyåˆ†åŒºï¼Œé€šè¿‡targetTaskIndex = hash(key) % numTaskså¾—åˆ°ä¸‹æ¸¸subtaskçš„ç´¢å¼•
        // å°†keyè¿›è¡Œæ”¾å¤§ï¼Œé˜²æ­¢flinkå†…éƒ¨é”®åˆ†åŒºhashåè¯·æ±‚è½åˆ°å›ºå®šå‡ ä¸ªsubtask
        // ä¸ä½¿ç”¨requestIdï¼Œè€Œä½¿ç”¨userId
        // req -> (Integer.parseInt(req.getRequestId().substring(4)) % parallelism) * x
        // int x = (int) Math.pow(parallelism, parallelism) % 2 == 0 ? (int) Math.pow(parallelism, parallelism) + 1 : (int) Math.pow(parallelism, parallelism);
        // req -> keyList.get(Integer.parseInt(req.getRequestId().substring(4)) % parallelism)
        // ä½¿ç”¨InferenceRequest::getRequestIdä½œä¸ºkeyï¼Œé…åˆrebalanceå®ç°å‡åŒ€åˆ†å¸ƒï¼Œåœ¨åç»­å¤„ç†ç®—å­ä¸­å†è‡ªå®šä¹‰çŠ¶æ€å­˜å‚¨ã€‚
        DataStream<InferenceResponse> responses = requests.rebalance().keyBy(InferenceRequest::getRequestId)
                .process(new KeyedProcessFunctionBatchProcessor())
                .name("Count Based Batch Processor");

        // ä½¿ç”¨ç»Ÿä¸€æ€§èƒ½ç»Ÿè®¡
        String experimentId = String.format("%d batch - %d requests", batchSize, maxRequests);
        responses.keyBy(r -> 0).addSink(new UnifiedPerformanceSink(
                        UnifiedPerformanceSink.ExperimentType.BATCH_ANALYSIS,
                        experimentId))
                .name("Count Batch Performance Sink").setParallelism(1);

        logger.info("ğŸš€ åŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹æµæ°´çº¿æ„å»ºå®Œæˆ");
        logger.info("ğŸ“Š æ ¸å¿ƒä¼˜åŠ¿:");
        logger.info("  1. çœŸæ­£æ”’å¤Ÿ{}ä¸ªè¯·æ±‚ç«‹å³å¤„ç†ï¼ˆä¸ç­‰æ—¶é—´ï¼‰", batchSize);
        logger.info("  2. ProcessFunctionæ”¯æŒä¸€å¯¹å¤šè¾“å‡ºï¼ˆä¸€ä¸ªæ‰¹æ¬¡â†’å¤šä¸ªå“åº”ï¼‰");
        logger.info("  3. State-basedç¼“å†²ï¼Œæ”¯æŒæ•…éšœæ¢å¤");
        logger.info("  4. Timerè¶…æ—¶ä¿æŠ¤ï¼Œé¿å…æœ€åå‡ ä¸ªè¯·æ±‚æ°¸è¿œç­‰å¾…");
        logger.info("  5. çœŸå®GPUæ‰¹é‡å¹¶è¡Œï¼Œä¸æ˜¯ä¼ªæ”’æ‰¹");

        logger.info("ğŸ“ˆ é¢„æœŸæ•ˆæœ:");
        logger.info("  - Batch-1: æ— ç­‰å¾…ï¼Œç›´æ¥å¤„ç†");
        logger.info("  - Batch-4: ç¬¬1ä¸ªè¯·æ±‚ç­‰å¾…æœ€ä¹…ï¼Œç¬¬4ä¸ªç«‹å³å¤„ç†");
        logger.info("  - GPUåˆ©ç”¨ç‡: å¤§æ‰¹æ¬¡æ˜¾è‘—æå‡ååé‡");
        logger.info("  - å»¶è¿Ÿåˆ†å¸ƒ: æ‰¹æ¬¡å†…è¯·æ±‚æœ‰ä¸åŒç­‰å¾…æ—¶é—´");

        // æ‰§è¡Œ
        env.execute("InferTuner Count Based Real Batch Analysis Test");

        logger.info("=== åŸºäºæ•°é‡çš„çœŸå®æ”’æ‰¹éªŒè¯å®Œæˆ ===");
    }
}
